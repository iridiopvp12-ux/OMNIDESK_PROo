import { GoogleGenerativeAI } from "@google/generative-ai";
import dotenv from "dotenv";
import fs from "fs"; 
import mime from "mime-types"; 

dotenv.config();

if (!process.env.GEMINI_API_KEY) {
    throw new Error("‚ùå GEMINI_API_KEY ausente no .env");
}

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// --- CONFIGURA√á√ÉO: GEMINI 2.0 FLASH ---
// O modelo 2.0 √© nativamente multimodal e muito r√°pido.
const model = genAI.getGenerativeModel({ 
    model: "gemini-2.0-flash-exp", 
    generationConfig: {
        temperature: 0.2, // Mant√©m a precis√£o para seguir o JSON
        maxOutputTokens: 2000,
    }
});

// Mem√≥ria Vol√°til (RAM)
const memory = new Map<string, string>();

const SYSTEM_PROMPT = `
IDENTIDADE: Voc√™ √© a J√öLIA, a triadora especialista e acolhedora do escrit√≥rio previdenci√°rio do Dr. Jos√© Lucas.

üß† DIRETRIZES DE INTELIG√äNCIA:
1. INTERPRETA√á√ÉO ROBUSTA: O cliente pode usar g√≠rias ou portugu√™s informal. Entenda a inten√ß√£o.
2. EMPATIA: Seja cordial e profissional.
3. MULTIMODALIDADE (IMPORTANTE):
   - Se receber √ÅUDIO: Ou√ßa com aten√ß√£o, entenda o problema relatado e responda como se fosse texto.
   - Se receber IMAGEM (DOCUMENTO): Confirme o recebimento ("Recebi a foto do documento") e extraia informa√ß√µes se necess√°rio.

üöÄ FLUXO DE ATENDIMENTO:
1. ACOLHIMENTO: Entenda o problema principal.
2. INVESTIGA√á√ÉO: Fa√ßa UMA pergunta por vez (Idade, Tempo de contribui√ß√£o, Motivo do indeferimento).
3. ENCERRAMENTO: Quando tiver o m√≠nimo para o advogado analisar.

üî¥ GERA√á√ÉO DE RELAT√ìRIO E TICKET (CR√çTICO):
Quando voc√™ decidir encerrar o atendimento para passar ao humano, diga sua frase de despedida e, IMEDIATAMENTE DEPOIS, gere um bloco JSON oculto EXATAMENTE assim (sem formata√ß√£o markdown):

[REPORT_START]
{
  "cliente": "Nome Identificado",
  "tema": "LOAS / Aposentadoria / Aux√≠lio / Outros",
  "interpretacao": "Resumo t√©cnico do caso (incluindo transcri√ß√£o mental de √°udios se houver).",
  "atencao": "Pontos de urg√™ncia ou perfil do cliente",
  "sugestao": "Agendar Consulta / Pedir CNIS / An√°lise",
  "prioridade": "medium"
}
[REPORT_END]

‚ö†Ô∏è REGRA FINAL: N√£o adicione \`\`\`json ou blocos de c√≥digo. Apenas as tags [REPORT_START] e [REPORT_END].
`;

// Fun√ß√£o auxiliar: Converte arquivo local para o formato do Google Gemini
async function fileToGenerativePart(path: string, mimeType: string) {
    const fileData = await fs.promises.readFile(path);
    return {
      inlineData: {
        data: fileData.toString("base64"),
        mimeType,
      },
    };
}

// Fun√ß√£o Principal: Gera resposta considerando Texto + Hist√≥rico + M√≠dia (Opcional)
export const gerarResposta = async (msgUsuario: string, contactId: string, mediaPath?: string): Promise<string> => {
    try {
        // 1. Recupera hist√≥rico
        let historico = memory.get(contactId) || "";
        
        // 2. Monta o Prompt (Array de conte√∫dos)
        const promptParts: any[] = [
            SYSTEM_PROMPT,
            "\n\n--- HIST√ìRICO RECENTE ---\n",
            historico,
            `\n\nCliente (Mensagem Atual): "${msgUsuario || '[Arquivo de M√≠dia enviado]'}"\n`
        ];

        // 3. Se tiver arquivo (√Åudio/Imagem), anexa ao prompt
        if (mediaPath) {
            const mimeType = mime.lookup(mediaPath) || 'application/octet-stream';
            const mediaPart = await fileToGenerativePart(mediaPath, mimeType);
            
            promptParts.push(mediaPart);
            promptParts.push("\n(O cliente enviou o arquivo acima. Analise o conte√∫do dele junto com o texto.)\n");
        }

        promptParts.push("\nJ√∫lia:");
        
        // 4. Envia para o Gemini
        const result = await model.generateContent(promptParts);
        const respostaFull = result.response.text();

        // 5. Salva no hist√≥rico (removendo o JSON t√©cnico para economizar tokens e n√£o confundir)
        const textoLimpo = respostaFull.replace(/\[REPORT_START\][\s\S]*?\[REPORT_END\]/, "").trim();
        historico += `\nCliente: "${msgUsuario || '[M√≠dia]'}"\nJ√∫lia: "${textoLimpo}"`;

        // Gest√£o de mem√≥ria (Janela deslizante)
        if (historico.length > 10000) {
            const corte = historico.length - 8000;
            historico = "..." + historico.substring(corte);
        }
        
        memory.set(contactId, historico);

        // Retorna a resposta completa (com JSON) para o whatsapp.ts processar
        return respostaFull;

    } catch (error: any) {
        console.error("‚ùå Erro AI Multimodal:", error.message);
        return "Desculpe, o sistema est√° processando muitas informa√ß√µes. Pode repetir a √∫ltima mensagem ou enviar em texto? üôè";
    }
};


